{
  "agent_id": "coder4",
  "task_id": "task_4",
  "files": [
    {
      "name": "README.md",
      "purpose": "Project documentation",
      "priority": "medium"
    },
    {
      "name": "utils.py",
      "purpose": "Utility functions",
      "priority": "low"
    }
  ],
  "project_info": {
    "project_name": "enhanced_cs.HC_2507.22665v1_Cluster_Based_Random_Forest_Visualization_and_Inte",
    "project_type": "computer_vision",
    "description": "Enhanced AI project based on cs.HC_2507.22665v1_Cluster-Based-Random-Forest-Visualization-and-Inte with content analysis. Detected project type: computer vision (confidence score: 6 matches).",
    "key_algorithms": [
      "Lying",
      "Visualizing",
      "Dominant",
      "Aid",
      "Visualization",
      "Similar",
      "Cut",
      "Heuristic",
      "Elbow",
      "View"
    ],
    "main_libraries": [
      "torch",
      "numpy",
      "pandas"
    ]
  },
  "paper_content": "PDF: cs.HC_2507.22665v1_Cluster-Based-Random-Forest-Visualization-and-Inte.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\n\u00a92025 IEEE. This is the author\u2019s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The final version of this record is available at: xx.xxxx/TVCG.201x.xxxxxxx/\nCluster-Based Random Forest Visualization and Interpretation\nMax Sondag , Christofer Meinecke , Dennis Collaris , Tatiana von Landesberger , and Stef van den Elzen\nA B C\nFig. 1: An overview of the visual analytics system. A) shows global information such as feature and class distribution, model accuracy,\nand predictions. Furthermore, it allows control of the number of clusters that are displayed and shows a 2D projection of the clustered\ntrees. B) The Feature Plot (top) shows how often a feature is used within a cluster at a specific depth in the tree and the Rule Plot\n(bottom) shows an aggregated view of the classification rules used in a cluster. C) Shows the decision trees within a selected cluster.\nAbstract \u2014 Random forests are a machine learning method used to automatically classify datasets and consist of a multitude of\ndecision trees. While these random forests often have higher performance and generalize better than a single decision tree, they are\nalso harder to interpret. This paper presents a visualization method and system to increase interpretability of random forests. We\ncluster similar trees which enables users to interpret how the model performs in general without needing to analyze each individual\ndecision tree in detail, or interpret an oversimplified summary of the full forest. To meaningfully cluster the decision trees, we introduce\na new distance metric that takes into account both the decision rules as well as the predictions of a pair of decision trees. We also\npropose two new visualization methods that visualize both clustered and individual decision trees: (1) The Feature Plot, which visualizes\nthe topological position of features in the decision trees, and (2) the Rule Plot, which visualizes the decision rules of the decision trees.\nWe demonstrate the efficacy of our approach through a case study on the \u201cGlass\u201d dataset, which is a relatively complex standard\nmachine learning dataset, as well as a small user study.\nIndex Terms \u2014Random Forest, Decision Tree, Tree clustering\n1 I NTRODUCTION\nMachine learning models are used in many application areas, from\npersonalized recommendation systems to large-scale decision systems\nin industry [46]. This presence of machine learning comes with chal-\n\u2022 Max Sondag is with University of Cologne, Germany and Maastricht\nUniversity, Netherlands. E-mail: max.sondag@maastricht-university.nl\n\u2022 Tatiana von Landesberger is with University of Cologne, Germany. E-mail:\ntlandesb@uni-koeln.de\n\u2022 Christofer Meinecke is with Leipzig University and ScaDS.AI\nDresden/Leipzig, Germany. E-mail: cmeinecke@informatik.uni-leipzig.de\n\u2022 Dennis Collaris and Stef van den Elzen are with Eindhoven University of\nTechnology, the Netherlands. E-mail: {d.a.c.collaris, s.j.v.d.elzen}@tue.nl.\nManuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication\nxx xxx. 201x; date of current version xx xxx. 201x. For information on\nobtaining reprints of this article, please send e-mail to: reprints@ieee.org.\nDigital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxxlenges regarding the black-box nature of these models, including issues\nof transparency, interpretability, and explainability [13].\nIn the case of tabular data, Random Forest (RF) [10] and other tree-\nbased models are popular and effective classification methods that still\noutperform neural networks [23]. RF is an ensemble learner composed\nof several decision trees, but despite their utility, the complexity of\nensemble models can obscure the understanding of how they arrive\nat their predictions. It may be possible to interpret a single decision\ntree [8, 55, 56], or to compare a small number of decision trees quite\neasily, but with increasing number of features and trees, this becomes\nchallenging [45,58]. Existing work on RF explainability mainly focuses\non feature contributions (e.g., [35, 65]), extracts decision rules (e.g.,\n[14, 41]), or aims to create a single tree summary from the whole\nensemble (e.g., [45,58]). Typically, all rules are combined into a single\nrepresentation of the full classification model, or the individual trees\nare presented in detail. Both methods are challenging to interpret and\nunderstand, and hide the multi-level structures present in the model.\nWe believe an RF model is not best explained with a single summary,\nbut through clusters of trees that are responsible for classification of\n1arXiv:2507.22665v1  [cs.LG]  30 Jul 2025\n\n--- Page 2 ---\ndata with specific characteristics. Understanding the different clusters\nin the model enables users to see how well specific parts of the data\nare covered by different trees. This provides insight into the robustness\nand confidence of the model by inspecting the cluster sizes, feature\ncharacteristics, and both common and outlier trees.\nWe propose an approach that aims to find a middle ground between\nvisualizing the entire model and visualizing a single tree to explain the\nmodel. For this, we leverage the structure in the decision trees to cluster\nthese based on their rules (paths). An important aspect of this approach\nis the selection of an appropriate distance metric. We focus on the rules,\nwhich allow us to include semantic as well as structural components\nof the trees. The final cluster-based visualization of the model should\nreduce the cognitive load while remaining (largely) faithful to the\noriginal model.\nFor the cluster-based visualization and interpretation of an RF model,\nwe propose a visual analytics system that uses three levels of granular-\nity. First, we show global information about the model and the dataset,\nshowing the overall classification results, accuracy, and feature distri-\nbution (see Figure 1a). Secondly, we create two visualizations that\naggregate the features and the rules of the decision trees in a cluster.\nBy distilling the complexity of RFs into a manageable set of trees, this\napproach can help to understand these models (see Figure 1b). Lastly,\nwe include a detailed view that shows all decision trees in a cluster,\nallowing users to inspect the behavior of individual decision trees on\ntheir dataset (see Figure 1c). Insights using our system help a variety\nof applications, ranging from diagnostics, refinement, decision support,\nand justification. For evaluation purposes, we present a case study on\nthe \u201cGlass\u201d dataset [21] and conduct a small user study in a think-aloud\nsetting. For this, we collect responses with the System Usability Scale\n(SUS) [12] and ICE-T [60] questionnaires.\nOur contributions are as follows:\n1.A new distance metric for comparing decision trees in a random\nforest based on both the predictions and decision rules (semantics\nand structure) .\n2.Two new scalable aggregation-compatible visualizations for ex-\nploring random forests based on their features and decision rules.\n3.A cluster-based visualization system for visualizing a random\nforest model using aggregation.\nThe paper is structured as follows: in Section 2 we discuss work re-\nlated to the visualization of decision trees, random forests, and distance\nmetrics for decision trees. Section 3 elicits the tasks we aim to support\nwith our approach. Next, we introduce and discuss our distance metric\nand the associated method of clustering the decision trees in Section 4.\nWe then use these methods in our interactive visualization approach\npresented in Section 5. Section 6 evaluates our approach with both case\nand user studies. Finally, limitations, directions for future work, and\nconclusions are presented in Section 7 and Section 8, respectively.\n2 R ELATED WORK\nCentral to our method for the visualization and interpretation of random\nforests are the visualization of clusters of decision trees that together\nform the random forest, and the visualization of individual decision\ntrees. To construct the clusters, we group together similar decision trees.\nFor this, we need a distance metric to determine the similarity between\nthe trees. In this section, we discuss work related to these elements;\nvisualization of decisions trees; visualization of random forests; and\nproposed distance metrics for decision trees.\n2.1 Visualization of Decision Trees\nAs decision trees represent a hierarchy, standard hierarchical visualiza-\ntion techniques and guidelines are applicable, as proposed by Elmqvist\nand Fekete [18]. The tree structure can be encoded explicitly or im-\nplicitly as surveyed by Schulz et al. [48]. Graham and Kennedy [22]\nprovide a survey on the visualization of multiple trees simultaneously,further explored for multivariate data by Zheng and Sadlo [66]. Build-\ning on this, several visualization and interaction techniques have been\ndeveloped to compare tree representations [11,33,40]). However, these\nstandard hierarchical data visualizations, as well as model-agnostic\nmachine learning visualizations (e.g., Confusionflow [25], and Model-\nWise [37]), do not leverage the unique properties of decision trees such\nas features used, split rules, and classification data flow.\nSplit rules are visualized using different idioms such as icicle plots [2,\n32], parallel coordinate plots [24], and adapted treemaps [15]. Li et\nal. [31] introduce a compact, barcode-inspired layout that enables the\ncomparison of multiple tree structures by encoding the tree with a single\nbarcode. However, for these paradigms it is more difficult to understand\nthe tree structure (e.g., paths), as this is not directly visualized.\nEMTree [8] uses a multiple linked view approach using treemaps,\nline-charts, bar-charts, and a node-link diagram to visualize the tree\nstructure. PaintingClass [55] shows the tree structure with a focus-and-\ncontext approach, always having a single node in focus represented\nby star- or parallel-coordinate plots. Ancestors of the node are drawn\nsmaller to the right, and descendants at the bottom. BaobabView [56]\nintegrates the tree visualization with the data visualization by explicitly\nshowing the data as size- and color-encoded Sankey flows on top of the\ntree structure. Also, Worland et al. [64] visualize the tree structure by\nvisualizing the classification boundaries at each level using a scatterplot\nand connecting linked data items. However, this method is not space\nefficient and introduces clutter due to many crossing edges, making it\nchallenging to interpret the tree structure and understand the splits.\nFor a more extensive and recent discussion of tasks and visualiza-\ntions tailored for decision trees and rule-based classifiers, we refer the\nreader to the overview presented by Streeb et al. [53].\n2.2 Visualization of Random Forest\nAs random forests consist of (potentially a large number of) decision\ntrees, visualizing them as a whole requires aggregation techniques.\nHowever, visualization of individual trees is possible if few trees are\ninvolved, and the trees themselves are rather simple with a low depth.\nTrees with a low depth can in general be achieved using different prun-\ning techniques [27]. In M\u00e9doc et al. [36] shallow trees (of maximum\ndepth 5) are visualized using icicle plots positioned in a grid. Fur-\nther linked visualizations provide additional interpretation mechanisms,\nsuch as a bar chart of feature importances and a scatterplot showing the\nresidual versus prediction for all regression trees. Also, TreePOD [39]\nvisualizes individual decision trees using pixel-based treemaps. The\ntreemaps show the (implicit) tree structure, where each class-colored\npixel in the contained rectangles represents a single data item. The\nsystem enables users to explore the relation between the number of\nnodes and the accuracy through a Pareto frontier of trees, guiding them\nto select the Pareto optimal tree. Individual trees can be inspected in\ndetail using the flow-based tree visualization of BaobabView [56].\nAs both the number of trees and their depth are typically large, most\nvisualization techniques rely on summarization and aggregation of\ndifferent aspects of the decision trees [4]. Wang et al. [61] present\nTimberTrek that visualizes a Rashomon set of more than a thousand\ndecision trees using a radial icicle plot. In the radial plot, the rules\nof the shallow decision trees are combined into a single hierarchical\nrepresentation. The individual trees can be explored in detail using\nadditional views with node-link diagrams. Next to visualizing extra\ninformation and aggregation (size reduction), the other main inter-\npretability strategies for random forests are rule extraction and local\nfeature-based explanations [4].\nRulematrix [38] visualizes rules derived from the decision trees as\ndifferent flows, horizontally branching from a main vertical data flow.\nAntweiler and Fuchs visualize rules together with a hierarchical radial\nnode-link diagram representing the trees [3]. Each rule is visualized\nseparately using a block diagram, potentially leading to scalability con-\ncerns as the number of rules can be large for a moderate-size random\nforest, as decision trees typically need to cover for different characteris-\ntics of the data. VisRuler [14] addresses this by presenting all rules in a\n2\n\n--- Page 3 ---\n\u00a92025 IEEE. This is the author\u2019s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The final version of this record is available at: xx.xxxx/TVCG.201x.xxxxxxx/\nsingle view using an adapted parallel coordinates plot. They present\na visual analytics system for extracting decision rules and use dimen-\nsionality reduction to project each decision tree classifier to a point.\nAnother solution to deal with scalability is by reducing the ruleset to\n\u201ccommon\u201d rules. Adilova et al. [1] focus on finding the best trimmed\nruleset and present ways to visualize these. Neto and Paulovich [41]\npresent an Explainable Matrix approach where rows are rules, columns\nare features, and cells are rules predicates, aiming to address both scal-\nability and interpretability. However, scalability remains a concern, as\nrules can be plenty, quickly rendering the rows too small.\nNext to rules-based visualizations, several methods focus on visualiz-\ning the feature contributions, e.g., using three-dimensional surfaces [62]\nor using Sankey-like visualizations showing the flow of items through\nthe different features, ordered by importance in the iforest system [65].\nThis typically reveals the relationships between features and predictions\nand enables easier case-based reasoning.\nFinally, several methods focus on explainability of the random forest.\nAria et al. [5] summarize a random forest with a single decision tree.\nSuch an approach provides valuable global insights that are not easily\nachieved through local analysis and visualization techniques. However,\nour approach has a different focus, aiming to identify and discover\ndifferent clusters of decision trees in the random forest, striking a bal-\nance between a pure global and local approach. Other methods retrieve\ninsights on the data rather than the model , e.g., RfX [17] demonstrates a\nvisual analytics system for Random Forest interpretation. Mazumdar et\nal. [34] present Random Forest Similarity Maps, addressing both scala-\nbility and interpretability of the model\u2019s inner workings by mapping the\ndecision trees to 2D using dimensionality reduction techniques. In our\nSidebar (Figure 1a), we use a similar projection for a quick overview\nof clusters of similar trees.\nAs a general observation, most visualizations are relying on color\nfor either the features and/or the classes involved, which limits the\nscalability of these. The dominant approach to visualize individual\ndecision trees is through tree structured Sankey-like data flows [56].\nFor Random Forests, two methods are prevalent: rules extraction and\nfeature based visualizations. For both, either the individual trees, and\nrules are shown, or an aggregate of all trees. Here we aim for a different\napproach, inspired by the work of Sondag et al. [51] we identify clusters\nof trees based on behavioral characteristics and visualize them using\nnovel interactive summaries.\n2.3 Distance Metrics for Decision Trees\nOver the years, a multitude of metrics have been proposed to compute\ndistances between decision trees. Chipman et al. [16] and Banerjee et\nal. [7] proposed three metrics, one based on prediction agreement on\na test dataset (actual class), one based on agreement in the leaf nodes\non a test dataset (actual node), and one based on split points. However,\nboth papers define the metric for split points differently.\nSemantic methods only look at the classification results of the given\ndata samples, e.g. two trees are similar if they predict the same classes\nfor the same data samples or end up in the same leaf node. This\ncomputes an agreement score, but ignores the thresholds used at the\nsplit points. Tan et al. [54] use a distance based on leaf agreement to\nselect samples from the dataset that explain the prediction of a class.\nAnother way to compute distances based on a dataset is to compute\nfeature contributions [42]. Thresholds are also ignored by methods\nthat define two trees as similar if they use the same split variables [7],\nwhich only shows differences if at least one variable is not used in a\ntree; otherwise, all distances are 0. These metrics do not fully capture\nthe underlying tree structure.\nThe split method in Chipman et al. [16] is based on Shannon and\nBanks method [49] and counts the number of nodes where the variable\nused for a split point is different with an optional penalty for the depth\nwhere the split occurs. This is similar to the idea of Laabs et al. [28],\nwhich defines two trees as similar if they use the same split variables,\nweighted by the depth and the number of times the variable is used.They showed that this approach can have advantages when choosing a\nrepresentative tree over the methods of Banerjee et al. [7]. A drawback\nof these methods is that they assign a non-zero distance to identical\ntrees that differ only in the order of their split points, even when the\nthresholds remain the same. Another structural approach is to transform\nthe node order into a string sequence, where two trees are similar if\nthe same sequences of split variables are used to predict a class [6, 17],\nwhich can be measured using the Levenshtein distance [30].\nNone of these methods includes the thresholds of the split points. In\ncontrast, our approach is based on rules and includes the actual split\nvalues. Each rule represents a path from the root to a leaf and consists\nof multiple split points, each defined as an interval. For each rule, a\nset of intervals is computed on the basis of the split points, with an\ninterval for each feature. Including the split values allows our method\nto capture the actual decisions made during the splitting process, rather\nthan just the selected features, as in other methods. A similar approach\nto compare rules is used by Adilova et al. [1] but, in contrast to them,\nwe focus on tree distances and include interval overlap to ensure that\ncases that do not overlap are further apart. Other rule-based approaches\nfocus on extracting logic rules from each path [34, 41], but do not use\nintervals to calculate distances.\n3 T ASK ELICITATION\nA variety of different visualizations for random forests and associated\ntasks have already been explored in Section 2.2. Many of these tasks\nare from the perspective of machine learning experts who develop\nmodels [36, 65], from the end-user who wants to understand how a\nsingle instance decision was made [3,4,65], or from users of the model\nwho want to generate a simplified model out of it [4,5,14,17,36,39,61].\nIn this section, we elicit tasks from practitioners who use decision\nforests in their applied research for data classification purposes, but\nwho are not machine learning experts themselves.\nWe use a semi-structured interview setup to determine how two\nexperts from the domains of computational modeling and geography\nare using random forests in their applied research. In particular, we are\ninterested in what analysis tasks they are using random forests for, what\ntheir current process and focus is, and what they would like to be able\nto do and achieve in an ideal case. The complete list of questions and\nanonymized transcripts are available in the supplementary material.\nIn order to structure the results of the interview, we used the catego-\nrization by Streeb et al. [53] for the tasks. The main category on which\nour interviewees focus when using random forests is on the validation\nandevaluation of the model: how good is the classifier working in\ngeneral? Are there classes or areas where it performs better or worse?\nIs it reliable enough to be applicable? Are known salient split points\nused? We also identified a desire to better understand the model: how\nconfident is the model in the results? What is the overall structure of the\nforest? Are there features that are particularly important for a class? For\nthe feature importance, they also express a desire to see the relations\nbetween features, as high correlations can indicate overrepresentation.\nBoth the evaluation and the understanding serve as a measure of\nthe trustworthiness of the model for the interviewees. They aim to\nestablish that the model is trustworthy enough such that they can use it\non real-world applications, and that there are no unexpected results or\nimportant classes/input clusters that are likely to be incorrect.\nFinally, both our interviewees are working with spatial data. Hence,\nthey are quite interested in seeing the visualization results on the spatial\noutput space as well. That is, seeing for regions in the space how\nreliable the model is. While important for these particular users, this is\nnot a problem that generalizes over all the use cases for random forests,\nas many datasets do not have this spatial component. Hence, we do not\naddress this directly in our system, but it may be interesting for spatial\ndata in particular to provide a two-dimensional view that allows for the\nvisualization and filtering of this data.\nFrom the results of these interviews, as well as surveying related\nwork, we aim to support the following tasks in our visualization. Users\nshould be able to:\n3\n\n--- Page 4 ---\nf1\nf2 f1f2\nf2\n1 2f1\n4 2T1 T2\n3 4 1 3Fig. 2: Two trees with a different order of split points but the same rules.\nThresholds for features f1and f2are omitted for illustration purposes. Our\ndistance metric would result in a distance of zero, while methods that only\nfocus on the structure of the tree would give a non-zero distance [17,28].\nT1understand the overall decision process of the random forest.\nT2understand how a particular decision is made.\nT3evaluate how well the model performs globally.\nT4evaluate model performance on specific input classes/clusters.\nT5analyze the importance of the features.\nWe additionally require that the following general constraint is satis-\nfied: the visualization should be a faithful representation of the under-\nlying model to generate trustworthy explanations.\n4 D ISTANCE METRIC & C LUSTERING\nOur idea is to use cluster-based visualizations that visually aggregate in-\nformation from several decision trees. For this, we draw on the concept\nof representative trees in order to reduce the amount of information that\nis visualized at once and help to make sense of a large number of trees.\nBefore visualizing the random forest model, a suitable distance metric\nis needed [16] to compute the clusters and select representative trees\nfor each cluster.\nAs a decision tree can be represented with a set of rules, we decided\nfor a rule-based approach that incorporates the thresholds that are used\nin the decision trees, ignoring their (path) order. Figure 2 shows an\nexample of why the order of the nodes (topology) is less important\nthan the rules. Our approach ensures that similarity reflects on the\ndecision logic, and not only the used features and the used predictions.\nFurthermore, we only compare rules that lead to the same predictions\nto include the semantic component and to ensure that the distances\nbetween trees correspond to meaningful differences in decision making.\nThe distance between two decision trees T1andT2is computed as\nthe average rule distance:\nd(T1,T2) =1\n|R(T1)|\u2211\nri\u2208R(T1)min\nrj\u2208R(T2)dR(ri,rj) (1)\nwhere R(T1)andR(T2)are the set of of rules (paths) from trees T1and\nT2, respectively and |R(T1)|is the number of rules in T1. For each rule\nriinT1, we find the closest matching rule rjinR(T2)that predicts the\nsame class, using the distances between the rules dR(ri,rj). For a given\nrule pair riandrj, the rule distance is the average interval distance\nacross all features:\ndR(ri,rj) =1\nFF\n\u2211\nf=1df (2)\nwhere Fis the number of features. If there is no rule that predicts\nthe same class, a maximum distance of 1 is assumed for dR. Let the\nintervals for a feature fin two rules be denoted as:\nI1= [a1,b1],I2= [a2,b2]\nThe interval distance [9, 44] for a feature fis defined as:\ndf=1\u2212|I1\u2229I2|\nmax(b1\u2212a1,b2\u2212a2)(3)The result is a vector for each tree that contains the distances to the\nother trees as its elements. We also tested methods based on prediction\nagreement, split points and structural similarity [6, 7, 16, 28] but the\ndendrograms for our test data did not have strong cluster separation\nor were influenced by outliers. Furthermore, while plotting the rules\nin 2D using their distances to each other and MDS, a good separation\ncould be observed between the clusters of rules.\nFor clustering, we experimented with density-based methods like\nDBSCAN and HDBSCAN, but these approaches failed to detect mean-\ningful clusters, likely because the vectors are derived from a distance\nmatrix. Consequently, a distance-based clustering method seemed more\nfitting. Furthermore, with density-based methods, not every point is\nalways assigned to a cluster, which is required for our approach.\nWe first calculate a complete linkage matrix as an agglomerative\nhierarchical clustering method [20]. This ensures that all points within\na cluster are relatively close to each other, leading to compact clusters.\nAdditionally, we tried single linkage, but this led to the chaining ef-\nfect, resulting in less satisfactory dendrogram cuts. The result of the\nlinkage is a dendrogram, which is then used by the dynamic hybrid cut\nalgorithm to decide the final cluster assignment [29]. The advantage of\ndynamic hybrid cut is the usage of dynamic branch cutting instead of a\nconstant height cutoff value for the dendrogram. This takes advantage\nof local properties in the branches and creates clusters automatically\nthat would otherwise be only identifiable by visualizing the dendrogram.\nIn practice, we computed the dynamic hybrid cut on the dendrogram\nwith varying minimum cluster sizes to enable users to interactively\nchange the number of visible clusters. Finally, we compute the repre-\nsentative tree for each cluster by choosing the medoid, which is the\ntree with the minimal distance to all other trees of the cluster. We use\nthis representative tree as a basis to map the rules to in the Rule Plot\n(Section 5.3) and the first tree in Section 5.4.\n5 V ISUALIZATION\nAn overview of the system is shown in Figure 1. We explain the\ncomponents of our system in order of decreasing aggregation. We start\nby explaining the components of the Sidebar with the global view of\nthe dataset and model (Section 5.1) as shown in Figure 1a. We then\nproceed with explaining the more detailed view of the clusters through\nthe Feature Plot (Section 5.2) and Rule Plot (Section 5.3) shown in\nFigure 1b. Afterwards, we present a fully detailed view of the individual\ntrees in the clusters (Section 5.4) shown in Figure 1c. We conclude by\npresenting the linked interactions present in the system (Section 5.5).\n5.1 Sidebar\nIn the Sidebar, several visualizations are presented that provide an\noverview of the distribution of the underlying dataset and the overall\nmodel performance, as well as the clustering and distances between\ndecision trees.\nTo visualize the distribution of features (Figure 3 top left), we use\nsmall area charts as scented widgets [63] with kernel density estimation\nusing the Epanechnikov kernel [19] to estimate the feature distributions.\nUsers can filter the value range to explain the behavior on specific\ninput clusters of interest ( T4). For each plot, a bandwidth is selected\nbased on Silverman\u2019s method [50] to prevent charts that are too noisy\nor too smooth. For categorical features, a histogram shows the value\ndistribution. As our design requires both colors for the features and\nthe classes, and there can be many features and classes present, we\ncannot easily use a categorical color scheme because of limitations in\nthe number of distinguishable hues and reusing colors between features\nand classes would risk confusion and reduce clarity. Hence, we instead\nuse two sequential color scales with different hues for the features and\nclasses, and use the same ordering for the features here as in the Feature\nPlot (see Section5.2) to reduce the difficulty of identifying features.\nTo visualize the model performance in general ( T3), we use a classi-\nfication matrix (Figure 3, bottom left) and display the overall accuracy.\nSimilarly to the features, using a categorical color scheme is not feasi-\nble here, and we use a sequential color scale of blue hues to minimize\nconfusion with the colorscale of the features.\n4\n\n--- Page 5 ---\n\u00a92025 IEEE. This is the author\u2019s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The final version of this record is available at: xx.xxxx/TVCG.201x.xxxxxxx/\nFig. 3: The Sidebar of our system showing the \u201cGlass\u201d dataset, with\nscented area chart widgets for features (top left), classes and their\n(mis)classifications (bottom left), interactive cluster control (top right),\nand projection of the decision trees with representative trees for each\ncluster highlighted (bottom right).\nFeaturedistribution\n5%Islan d\n29% Bill_Length8%Bill_Depth\n54% Flipper_Length4%Body_Mass\nfortherootnode\nFeaturedistribution\nfordepth1nodes\nFeaturedistribution\nfordepth2nodes\nFeaturedistribution\nfordepth3nodes0%Sex\nFig. 4: The Feature Plot visualizes the distribution of features in a (cluster\nof) tree(s) per level. The most important features are automatically placed\nnear the top as these are split on first by decision trees.\nTo enable users to change clustering, we use a scented area chart\nwidget to display how the number of clusters depends on the minimum\ncluster size parameter of the clustering algorithm. Users can select the\ndesired aggregation level with direct manipulation using a slider. By\ndefault, this is set using an approach similar to the elbow method by\ndetecting where the maximum change in slope is and then selecting the\nsubsequent point where the slope change reaches minimum. Linked to\nthis slider is the projection view that shows a two-dimensional Multi-\nDimensional Scaling (MDS) plot of the decision trees. We chose\nMDS because it allows us to visualize the trees based on their pairwise\ndistances. This also makes the data easier to interpret, as the plot\ntruthfully reflects the relative distances between the trees. For each\ncluster, the convex hull is computed, and the representative tree is\nhighlighted.\nFinally, users can select either the (\u201cGlass\u201d [21] or \u201cPenguin\u201d [26])\ndataset that will be used in the user study, or upload their own dataset.\nWhen uploading a dataset, it is automatically processed using the\nstandard random forest algorithm of scikit-learn [43] and visualized.\nClassesFeatu res\nclassified asBilllength\nalways above\n30% forGentoo\nAdelie Adelie\nclassified as Gentoo AdelieFig. 5: A Rule Plot that shows the decision trees in one cluster. Aggre-\ngated decision rules are displayed vertically along their features, with the\nclassification matrix for the rule at the bottom.\n5.2 Feature Plot\nAfter grouping the decision trees into clusters, users need to be enabled\nto analyze the clusters in a concise and comprehensible manner. For\nthe visualization of the cluster of trees, we need a scalable visualization\nthat both supports individual trees, and a cluster of multiple trees. In\ngeneral, to understand the behavior of the random forest, we need to\nexplore and understand the high-level characteristics of the clusters. To\nthis end, the tree-structure of the individual trees is less important, but\nwe rather want to understand for each cluster:\n\u2022 what features are used in the trees ( T1,T4);\n\u2022 what is the importance of each feature ( T5);\n\u2022 how similar are the features used ( T3,T4); and\n\u2022 how complex/deep are the underlying trees ( T1);\nFor this, we designed a novel visualization: the Feature Plot (see\nFigure 4). Each row in a Feature Plot represents one level of the tree(s).\nThe number of rows is therefore equal to the maximum depth of the\ncontained trees. This provides a quick overview whether the trees in\nthe cluster are shallow (few rows) or deep, hinting at the complexity of\nthe trees. For each level, we determine the frequency of the features\nthat are used in the underlying trees. We then divide the rectangular\nrow into smaller rectangles, one for each unique feature used, and scale\nthese horizontally proportional to their frequency. Each rectangle is\ncolored according to the associated global feature color. This process\nis repeated for each level. For each level in the Feature Plot, the order\nof the features is consistent to enable comparison and quick lookup.\nThis Feature Plot aggregate visualization provides additional cluster\ninformation compared to feature importances alone: 1) it shows what\nfeatures are used in the tree most (size of the rectangles), 2) what their\nimportance is (higher features are considered more important, as they\nsplit the dataset early on and thus have a higher discriminative power),\n3) how similar the features used are (uniform colors or different ones\nthroughout the levels), 4) how complex they are (many different features\nat the levels or just a few), and 5) how the contained trees are shaped\n(equal depths or varied). Many interesting insights can be gained from\nthe plots; we expect a limited number of features at the higher levels,\nagreed upon by the underlying trees. More features in the middle levels,\nas diversity grows with each level. And few features at the lowest levels\nsuggest that there are only a few specialized (overfitted) deeper trees.\nAdditionally, we can derive what features are important at each level,\nand quickly identify whether features are used at all. We layout the\nFeature Plots in a (rectangular) grid and sort them based on cluster size,\nstarting with the largest cluster. This provides a quick overview of both\nthe number of clusters as well as their size.\n5\n\n--- Page 6 ---\n5.3 Rule Plot\nTo visualize the decision rules present in a cluster of trees, we use a\nsecond novel visualization: the Rule Plot (see Figure 5). This allows\nus to visualize the overall decision process in the model ( T1), as well\nas to understand the decision process for a particular rule ( T2after\nfiltering). As the number of decision rules in a decision tree is equal to\nthe number of leaves, even for shallow trees, it is infeasible to visualize\nall decision rules individually. Instead, we map the set of rules R(c)\nwithin a cluster onto a representative tree Trthat is the medoid in\nthe cluster, and visualize all rules through this representative. This\nallows us to show all rules in the decision trees in this cluster using\nvisual aggregation, in contrast to simplifying to a single decision tree\nor showing only a representative, which would inherently lose some\nrules.\nLetR(T)be the set of decision rules for tree T. Then, for each tree T\nin a cluster c, we map each decision rule r\u2208R(T), towards the closest\ndecision rule r\u2217\u2208R(T\u2217)of the representative tree T\u2217of the cluster c.\nThe distance from rule rtor\u2217is defined as in Section 4. As an end\nresult of this process, every rule rin our cluster cis mapped to one of\nthe rules r\u2217of the representative tree T\u2217, with R(r\u2217)the set of decision\nrules mapped to r\u2217.\nUsing an appropriate distance metric is crucial as otherwise the visu-\nalization of these aggregations will not yield useful results. The most\nimportant factor is that we are mapping rules resulting in the same\noutput classification, as otherwise we need a much more complicated\nvisualization design for the mapping to split the differences apart. Sec-\nondly, we would like the rules to be similar in nature, i.e., have similar\nranges for each feature values. This relates back to our choice for the\ndistance metric used for distances between rules in Section 4.\nUsing the rule mapping, we then visualize the aggregated rules R(r\u2217)\nfor each rule r\u2217\u2208R(T\u2217)in the representative tree T\u2217using a vertical\ncolumn. We place the features vertically in the same order as in the\nSidebar. For each feature, we use a vertical heatmap to visualize how\noften each part of the feature range is used in R(r\u2217)using opacity\nblending. The darker the area, the more rules in R(r\u2217)use this part\nof the feature range. In Figure 5 we see an example of this in the bill\nlength where all involved rules for Gentoo are above the 30% mark,\nand even darker areas above the 70%. Below the vertical heatmaps for\nthe features, we use a stacked-bar chart of the classification results of\nR(r\u2217)for the test data to complete the Rule Plot.\nWe use the width of the heatmaps to highlight those rules that are\nmost often applied by scaling them based on the number of classifi-\ncations made with this rule. We ensure that lesser used rules remain\nvisible by capping the scaling at a factor 10. We place the rulesets\nr\u2217\u2208R(T\u2217)side by side, sorting the ruleset using a 1-dimensional em-\nbedding of the distances between the rules of the representative trees\nT\u2217. This ensures that similar rules are close to each other, allowing\nfor easier pattern identifications. Black vertical bars are positioned be-\ntween groups of rules with different classification outcomes, to visually\ngroup these together and make it easier to identify the groups.\n5.4 Decision Trees within Clusters\nTo provide a detailed view of the individual decision trees, we visualize\nall decision trees as node-link diagrams starting with the representative\ntree for a selected cluster (See Figure 1c). For this, we use the enhanced\nReingold-Tilford algorithm for variable-sized nodes [57]. As decision\ntrees are often visualized as node-link diagrams, this view should\nhelp users become familiar with the visualization system and help the\nlearning process. For each tree, the accuracy of the training and test\ndata is visible together with a tree number. We use both training and\ntest data to prevent unused paths in the decision trees.\nAn example decision tree explaining the node design is shown in\nFigure 6. The nodes are either feature split points and class predictions.\nFor each split point, we visualize the node as a kernel density estimation\n(KDE) plot of that feature together with a black line showing the split\npoint. If a feature appears multiple times along a path in the decision\ntree, the previous split points are used to color the intervals outside the\ncurrent range in gray. The prediction nodes show the target class\u2019s text\nlabel together with a stacked bar that shows the (miss)-classification\nFiltered\nrange\nfrom\npreviou s\nsplit\npoints Split point1\n3correctly classified2\n3incorrectly classified\nasGentooFig. 6: A single decision tree from the \u201cPenguin\u201d dataset. Internal nodes\nshow the active feature distribution and the split points. Leaf nodes show\nthe classification matrix for the decision path.\nUnfiltered cluster Path filtered incluster\nbill_depth <15\nFig. 7: Filtering based on bill depth below 15. In both the Feature Plot\n(top) and Rule Plot (bottom), decision rules and path that cannot have\nbill depth below 15 are hidden. In the Feature Plot we see the updated\ndistribution of features, showing that all features remain relevant for the\nclassification. In the Rule Plot we see the majority of penguins with small\nbill depths are from the Gentoo species, although there are a few from\nthe Adelie species as well.\nthrough class colors. We use a KDE to visualize the split value to be\nin line with the presentation of the features in the feature chart, to be\nconsistent with the colors in general, and to give an explanation how\nthe decisions made relate to the distribution of the features.\nThe edges are drawn using B\u00e9zier curves to support easier line\nfollowing through continuity. An edge starts at the split point of the\nparent and ends at the center of the child. Each edge has a thickness\ncorresponding to the number of samples in the dataset that follow this\npath in the tree (similar to [56]). The color of an edge is based on the\nclasses of samples that pass through it. This enables users to quickly\nsee which paths are important and what is the dominant class of a path.\n5.5 Interactions\nAs previously presented, our system consists of multiple linked views\nshowing the overview of the data in the Sidebar, a more detailed clus-\ntered view in the middle, and the decision trees themselves on the right.\nWe have linked these views using filtering and brushing (highlighting).\nA video of all interactions is available in the supplementary material.\nFiltering Through filtering the dataset, users can zoom in on particular\nfeature values and (mis)classifications of interest to better understand\n(T1,T2,T4, T5 ) the decisions made by the model. For every decision\nrule, we can filter on three different components: (1) The value ranges\nfor each feature that are valid within this rule, (2) The output classifi-\ncation of this rule, and (3) Misclassifications that this rule has made.\nFor (1), we filter the data using the Distribution plots for the features\n6\n\n--- Page 7 ---\n\u00a92025 IEEE. This is the author\u2019s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The final version of this record is available at: xx.xxxx/TVCG.201x.xxxxxxx/\nin the Sidebar. Users can drag the areas to select the value ranges of\ninterest for each feature. We then filter out a decision rule dif there\ncan be no instance that satisfies the selected value ranges. For (2) and\n(3) we combine the selection of it using the classification matrix in the\nSidebar. Users can select specific (mis)classifications or an entire class\nto select all classifications by clicking on them. We then filter out a\ndecision rule dif the selected (mis)classifications are not present in d.\nOnce we know which decision rules should be visualized, we can\nupdate the other visualizations to highlight this. For the decision tree\nvisualization, this is simple as we simply fade out any paths correspond-\ning to inactive decision rules, corresponding to standard dimming, to\nretain the overview.\nFor the Rule Plot, we do not visualize any of the decision rules that\nare filtered out. Fading here is not feasible, since opacity is used as a\nvisual variable. After filtering for the Rule Plot, there is a choice to\nre-normalize the data in the vertical heatmap. The advantage of this\nwould be that the filtered rules would have maximal visibility. The\ndownside is that filtering a value range would paradoxically increase\nthe visibility of the least-specific rules, as these are the last ones to\nbe filtered out. Hence, we decided to not re-normalize the data, and\nkeep the filtering more intuitive and stable at the cost of slightly lesser\nvisibility. An example of this filtering is shown in Figure 7.\nIn the Feature Plot, we are not visualizing the rules directly. Instead,\nwe visualize how often features are used per level lof the tree, which\ninformation is not contained in a decision rule as it is topology unaware.\nHence, we filter based on the decision paths in a cluster. Similarly\nto decision rules, we can filter out decision paths that do not lead\nto the selected (mis)classifications. For the feature values, for each\nnode vat depth lin a decision path pwe consider the decision rule d\nformed from the root of ptov, and filter in or out this node based on\nd. As decision rules only get stricter the further down pwe go, this\nensures a consistent filtering strategy of the nodes by showing subpaths\nstarting from the root. For each level land feature f, we calculate the\npercentage of nodes in the decision paths at depth lthat are filtered.\nWe then visualize this percentage using a white area on the feature to\nbe consistent with the Rule Plot filtering within this interaction. An\nexample of this filtering is shown in Figure 7.\nHighlighting Hovering over a feature in any of the views highlights\nthis feature in all views. Aside from the advantage of being able to\nsee the feature of interest clearly in all views, clusters, and decision\ntrees in one go, it also helps alleviate some of the issues with choosing\na quantitative color scheme for categorical data. By highlighting the\nfeature everywhere, users can quickly see which feature is which.\nIn most plots, highlighting is achieved by reducing the opacity of\nall other features. In the Rule Plot, this, however, is not an option, as\nopacity is already used in the vertical heatmaps as a visual variable.\nInstead, we increase the width of the black horizontal bar above and\nbelow the feature to highlight it (see the black bars around Calcium in\nthe figure on the right).\nOther interactions Aside from the linked interaction, several other\ninteractions in the system are available. We briefly list these here.\nSelect level of aggregation In the Sidebar users can select the re-\nquired level of aggregation. After selecting the desired aggregation\nlevel, new clusters are generated and visualized in the middle view\nusing the Feature and Rule Plots. Similarly, the decision trees of the\nclusters are updated as well.\nCluster selection By selecting a Feature or Rule Plot within a cluster,\nusers are shown the decision trees for this particular cluster.\nProjection hovering By hovering over a point in the projection view\nin the Sidebar, all points corresponding to decisions trees in the same\ncluster are highlighted.\nZooming and panning In the Rule Plot and Feature Plot view, as\nwell as the decision tree view, zooming and panning are implemented\nto allow for details to be more easily perceived.\nTooltips Tooltip information is available for the classification ma-\ntrices showing exact values (including those in the Feature Plot), for\nthe distribution plots showing exact values, split points on the decision\ntrees, and the number of samples for an edge in a decision tree. These\nenable users to obtain the exact information where relevant.6 E VALUATION\nTo evaluate our approach, we follow standard approaches for evaluating\nexplainers for random forests [14, 17, 65], by presenting a case study\nto demonstrate how our approach resolves the tasks in Section 3. In\naddition, we conducted a small qualitative user study to determine the\nusability of the system and identify areas of improvement.\nMost papers explaining random forest use different datasets, and\nhence there is no standard baseline dataset to compare with. For our\nevaluation, we picked two different datasets: (1) The \u201cPenguin\u201d [26]\ndataset cut off at a depth of 4 to intentionally introduce misclassifi-\ncations. We use this in our user study as a training dataset due to its\nlimited complexity (3 classes, 6 features, clear distinction between\nclasses with 99% accuracy). (2) The \u201cGlass\u201d [21] dataset, which is\na more complicated dataset with 6 classes, 9 features, and significant\noverlap between classes (84% accuracy from the random forest). The\ncomplexity of the dataset should give us a representative indication of\nthe efficacy of our approach on real-world datasets. Additionally, it is\na well-known, open-source and standard dataset that sees active use,\nwhich ensure ease of reproducibility and comparability. Finally, both\nthe number of features and classes, while larger, are still within the\nscalability capabilities of our approach.\n6.1 Case Study\nTo demonstrate how our approach can resolve the tasks in Section 3\nwe perform a case study using the well-known \u201cGlass\u201d [21] dataset,\nhighlighting what the user can do with the insights. A complete view\nof our system is shown in Figure 1.\nWe start by evaluating how\nwell the model works globally\nusing the classification plot ( T3).\nMost of the classes are classified\nwell (84% accuracy), but for\nclass Building a significant frac-\ntion (25% as shown on hover) of\nthe instances are misclassified\ninto class Building float ( T4).\nInsight: Combined with the imbalance in class frequency, this shows\nthe modeler which additional data is desired in case the model is un-\nsuitable or needs to be improved for their purposes.\nWe then investigate deeper into how\nthe classification Building is deter-\nmined and their misclassifications ( T1,\nT5). We filter the classification of\nBuilding float to its misclassification\nBuilding and the correct classification\nBuilding float, which results in two vis-\nible columns per cluster in the rule plot.\nOne such cluster is shown on the left.\nIn the right grouped column, we see the\ngeneral classification rules used to cor-\nrectly classify Building, rules that do\nnot follow this classification are faded\nout. For some features, there are strong\nsplit criteria with a vast majority of the\nrules and classifications made using a similar threshold (i.e. the high-\nlighted featured Calcium for values of 8.3). In the left grouped column,\nwe have the misclassifications from Building float to Building. Rules\nthat do not have this misclassification are faded out. From the classifica-\ntion barcharts at the bottom, we see that this misclassification is made\nin most rules, although not by significant amounts in many of them.\nWe also see that many of the rules where misclassifications are made\nfollow quite similar patterns to those of the correct classifications. This\nindicates that there are only small differences between these two classes,\nand that it is a combination between multiple features. Insight : With\nadditional domain knowledge, users can determine if there is indeed\na blurry line between the two classes, or whether additional features\ncould be introduced to make this distinction more clear. Moreover,\nit tells them that classifications between these two classes are quite\nsensitive to noise.\n7\n\n--- Page 8 ---\nContinuing by looking at the filtered\nFeature Plots of cluster 50 for these two\nclassifications, we can see which fea-\ntures are being split and how high in\nthe tree. We notice that all features\nare present, but some only become rele-\nvant much deeper (i.e. Refractive Index,\nfirst feature, and Iron, last feature) indi-\ncating that this is a finer split to distin-\nguish between two final classifications.\nInsight: In contrast to the two clusters in Figure 8, there is more variety\nin splits in cluster 50. This indicates that many trees are substantially\ndifferent, and there is difficulty in generalizing a classification for these\nspecific two classes. This could also indicate that one cannot easily\nremove any feature from the model as all features are used. Hence,\nusing less features to reduce the cost of data collection could come at a\ncost in distinguishability between these two classes.\nFig. 8: The clusters with different features of importance shown.\nWe go back to the unfiltered view (see Figure 8) of the data to\ndetermine the general features that are most important for the model.\nIn the Feature Plot, we see that three different features are considered\nimportant. Barium is always used as the first split point in two of\nthe clusters, while in the other cluster it is much more balanced with\nMagnesium and Sodium also being often present in all trees. We can\nalso see this split in the rule plot of the cluster without Barium as the\nfirst split point. The rules are much more complicated than in the others,\nas barium is used to split much later.\nWe can validate this by\nlooking at the node-link view,\nwhere for the clusters with\nBarium as a split point, many\ntrees make classifications at a\nlow depth with perfect accuracy.\nIn contrast, for the cluster\nwhere Barium is not present in the first level of the Feature plot, these\nimmediate classifications at low depth are not made. Insight: This\ngives the user insight in the different ways the classifications are being\nmade by the random forest and shows the simple and complex cases.\nWe continue by drilling down on a specific instance,\nwanting to know how this obtained a particular classifi-\ncation (T2). We input the feature values of an instance\nin the filtering, and see the rules being used for this in-\nstance. In addition, we can see how sensitive these rules\nare to changes, i.e. how much of a permutation is re-\nquired before a different rule would need to be followed.\nIn general, for a single instance, multiple rules can be\nactive due to the nature of the random forest. While the\nRule Plot visualization makes it possible to view the ac-\ntive rules for an instance, it is still somewhat difficult to\nview several rules in different clusters and compare them.Insight: For this particular case, we see that most trees capture it using\na very similar rule that has narrow ranges for Sodium (2ndrow), Barium\n(8throw) and Iron (9throw). This indicates that the classification of\nthis instance is quite sensitive to changes in these values.\nFrom the case study, it can be seen that most tasks can be performed\nwith the system, and they lead to non-trivial insights into the data. The\nvarious visualizations allow for both detailed views as well as keeping\nthe general overview, and the linking between them through interaction\nis crucial to control the desired aggregation level for the task.\n6.2 User Study\nIn addition to the case study, we perform a small user study to gain an\nindication about the usability of the tool using a think-aloud method-\nology. For this we recruited two domain experts, who had not been\ninvolved with the tool in any way. Both participants regularly work\nwith machine learning tools, with one participant actively working with\nrandom forests.\nBefore the study started, the participants were informed about the\ngoal of the study and were asked to fill in a consent form for permission\nto use their responses in this study. It was made clear that consent could\nbe withdrawn at any point during the study.\nWe then start the study with a short reintroduction of random forests\nand explain how the various components of the system work, before\nasking the participants to explore the \u201cPenguin\u201d training dataset.\nAfter this initial exploration, we switch to the \u201cGlass\u201d dataset, and\nask the participants to complete the following tasks sequentially.\n1. What are the most important features in the model? (T5)\n2. How well is the model performing? (T3)\n3. Which class is misclassified the most? (T4)\n4.How does the model decide that an instance belongs to class\nHeadlamps (T1+T4)\n5.What are the factors resulting in misclassification of Building\n(T4)\n6.How representative are the clusters shown of the underlying ran-\ndom forest?\nAfter the participant finished all tasks, we ask them for open-ended\nfeedback on the tool. Furthermore, we ask them to complete the SUS\nsurvey [12] and ICE-T [60] survey to gain additional information on the\nuser-friendliness and usability of the tool as a whole. The anonymized\nnotes taken, as well as the SUS and ICE-T scores, are available as\nsupplementary material.\nResults\nThe domain experts were able to make sense of the interactions within\nthe system, and these helped when trying to understand the relationship\nbetween all the views. Especially the linking from the features to\nthe Feature Plot, Rule Plot and decisions trees was found helpful, as\nthis helped clarify how the components were linked and gave a clear\nreference for the colors of the features and classes.\nBoth participants indicated that the variety of different features and\nviews were useful to them. They also mentioned that there were a lot of\ndifferent views to keep in mind and remember, and felt they still have\nthings to learn from the system by the end of the session.\nThe decision tree view was found useful for both participants, as it\nwas a more familiar view and easier to comprehend. Both participants\nused it extensively to validate their findings and generate potential\nhypotheses. Showing the classification matrix in the leaf nodes and\nthe feature distributions in the internal nodes did not appear to make it\nmore complex to comprehend, and was found useful in specific cases.\nThe initial three tasks were all able to be resolved well by the par-\nticipants. All views within the system were used for these tasks. For\ndetermining (mis)classification (4,5), the participants found multiple\ndifferent factors, but since there is no clear-cut answer involving only\none feature, they were unsure whether they had sufficient information.\n8\n\n--- Page 9 ---\n\u00a92025 IEEE. This is the author\u2019s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The final version of this record is available at: xx.xxxx/TVCG.201x.xxxxxxx/\nFor the last task (6), the more novice participant was unsure how\nto assess how representative the clusters shown were of the underly-\ning random forest, as they had not fully internalized all the relations\nbetween the views. The other participant did not have such issues and\nwas able to use all views well to answer this question. Both participants\ninitially struggled to understand how the clustering was done in the\nSidebar view. While they managed to change the aggregation level and\ndiscover how it worked, it was not intuitive to them, indicating that\ninteraction for the level of aggregation selection could be improved.\nThe participants also struggled with the size of the classification\nmatrix underneath the clusters. While it was successful in indicating\nthe major classes for a ruleset, obtaining more details (in particular\nexact numbers) by hovering over the rule was difficult due to the small\nsize of the matrix without zooming in excessively.\nFinally, the SUS survey results in a score of (70 and 82.5), placing\nit above the average of 68 [47]. The ICE-T [60] which is more visu-\nalization specific gives a score of (6.02 and 5.65) out of 7. Together,\nthese two surveys indicate that participants found the system usable\nand useful.\n7 D ISCUSSION AND LIMITATIONS\nIn our user study, we noticed that the clustering interaction for the\nlevel of aggregation selection was not sufficiently intuitive. Our ap-\nproach uses a hierarchical clustering method, which is well suited for\nan interactive system, but the method of setting the threshold can be\nimproved. For example, the possibility of manually setting the cuts\nin a dendrogram would give the user more control [59] and insight\ninto the method. However, this poses challenges for visualizing such a\ndendrogram in a scalable manner.\nWhile the classification bar charts at the bottom of the Rule Plots give\na good idea of the distribution of misclassifications, we also noticed\nthat it is difficult to determine exact values. Alternative visualizations\nor interactions should be considered here to mitigate this effect.\nOur current visualization approach allows the analysis of the model,\nbut misses an instance-based perspective, such as tracing how the model\nbehaves for a specific sample in the dataset. This could be resolved\nby highlighting a selected data sample in the visualizations. A cluster-\nbased approach to visualizing random forests offers a middle ground\nbetween the extremes of local analysis and full aggregation. Compared\nto analyzing individual decision trees, clustering reduces cognitive\nload by grouping structurally and functionally similar trees, allowing\nusers to identify representative patterns without becoming overwhelmed\nby the forest\u2019s complexity. This enables general insights into model\nbehavior while preserving important variability across subgroups of\ntrees. In contrast, aggregating all trees into a single summary tree\noffers simplicity and ease of interpretation, making it appealing for\nnon-expert users. However, this simplification can obscure important\nvariability and rare but meaningful decision paths. Clustering avoids\nthis trade-off by preserving structural diversity within each group while\nstill offering a compressed, interpretable view of the model. However,\nthe cluster-based approach also introduces challenges. It depends on\nthe quality of the clustering algorithm and the chosen distance metric,\nwhich may not always reflect meaningful semantic differences for all\ntasks. Additionally, users may still need to interpret multiple cluster\nrepresentatives, which can introduce complexity, particularly if the\nforest exhibits high heterogeneity.\nIn terms of scalability, our approach scales well with regard to the\nnumber of trees. However, it is limited in terms of the number of fea-\ntures and classes as we are using color to represent these, which might\nhinder real-world adoption. As the number of categories increases,\ndistinguishing colors on a sequential scale becomes more difficult. Al-\nthough highlighting and selection interactions help mitigate this effect,\nit remains a challenge for datasets with many features. A possible\nsolution is feature aggregation or selection, which would result in some\ninformation loss. Further, custom colorscales could be used for a spe-\ncific dataset. Additionally, performance issues may arise when trees\nbecome deep and complex. In this case, a progressive analytics ap-\nproach [52] could help by analyzing a subset of trees, providing a first\ninsight into important features, rules, and the cluster.Our system is specifically made for visualizing random forests, but\nthe Feature Plot, the Rule Plot, and the decision tree visualization\ncan also be used to visualize singular decision trees. The Feature and\nRule Plot may be usable for other types of classification algorithms as\nwell, as long as decisions paths (Feature Plot) or decision rules (Rule\nPlot) can be generated through the approach. The clustering approach\nitself can be extended to general ensemble techniques for classification\nas well, requiring only a distance metric and a way to visualize the\naggregation.\nIn general, by visualizing the distributions, classification results,\nas well as the random forest, common fundamental mistakes such\nas using the wrong encoding for a feature (quantitative instead of\ncategorical), using the wrong technique (Random forest not classifying\nit well enough, or a single tree being sufficient), or having the wrong\nfeatures can be brought to light in an intuitive way. These are often\nsimple issues to resolve when detected, but nonetheless have a major\nimpact if they are not spotted.\nThe field of random forest visualizations is wide, and an in-depth\ncomparison of the different approaches with standard tasks and datasets\nis needed, as well as an insight-based evaluation for real-world datasets.\nCurrently, such a comparison is not possible as the systems have been\ntested on too diverse tasks and datasets. The situation is similar for\ndistance metrics for decision trees. Some studies compare them [28],\nbut to the best of our knowledge there is no in-depth comparison of\ndifferent semantic, structural, and rule-based approaches. In addition,\nwhile it is possible to construct edge cases for different metrics, it\nis unclear how often these cases appear in random forests trained on\nreal-world data.\nFinally, while we have not included it into our system, it is never-\ntheless of interest for spatial data to allow for spatial data selection\nmethods. Currently, we use scented widgets with brushing for the fea-\nture selection, but alternative approaches such as selection on a matrix,\nparallel coordinate plots, or directly on a map could allow for a more\nnuanced filtering.\n8 C ONCLUSION\nIn this paper, we introduced a novel visualization approach to enhance\nthe interpretability of random forests by clustering similar decision trees\nbased on both their semantics andstructure . For this, we introduce\na new distance metric that can be used to determine decision tree\nsimilarity.\nOur approach allows users to gain insight into the overall behavior\nof the model without being overwhelmed by individual trees or relying\non oversimplified summaries of the entire classifier. To support this,\nwe proposed two new scalable visualization techniques: the Feature\nPlot, which reveals the hierarchical structure of feature importance\nacross clusters in the forest, and the Rule Plot, which presents the\ndecision-making logic within clustered trees.\nWe implemented these in a visual analytics prototype solution, sup-\nporting the user workflow through linking and brushing of the different\ncomponents. Furthermore, we show how the linked visualizations relate\nto common interpretability tasks. Our case and user study demonstrate\nthe effectiveness of our approach in improving model transparency.\nFuture work could explore refining the distance metric and clustering\nmethod to further aid model interpretability. Additionally, it would be\ninteresting to explore how our visualizations and general clustering-\nbased approach can be adapted to other rule-based and tree-based\nmodels. Overall, we believe that, with our approach, we have added\nanother useful tool to the user toolbox to increase model transparency.\nACKNOWLEDGMENTS\nThe authors wish to thank Sem Lommers for initial exploration of the\ntopic and interesting discussions. Stef van den Elzen is partially sup-\nported by AI4Intelligence with file number KICH1.VE01.20.011, partly\nfinanced by the Dutch Research Council (NWO). Christofer Meinecke\nacknowledges the financial support by the Federal Ministry of Educa-\ntion and Research of Germany and by S\u00e4chsische Staatsministerium\nf\u00fcr Wissenschaft, Kultur und Tourismus in the programme Center of\nExcellence for AI-research \u201cCenter for Scalable Data Analytics and\n9\n\n--- Page 10 ---\nArtificial Intelligence Dresden/Leipzig\u201d, project identification number:\nSCADS24B. Tatiana von Landesberger acknowledges the financial\nsupport by BMBF Project Risk Principe and WarmWorld.\nREFERENCES\n[1]L. Adilova, M. Kamp, G. Andrienko, and N. Andrienko. Re-interpreting\nrules interpretability. International Journal of Data Science and Analytics ,\npp. 1\u201321, 2023. doi: 10.1007/s41060-023-00398-5 3\n[2]M. Ankerst, M. Ester, and H.-P. Kriegel. Towards an effective cooperation\nof the user and the computer for classification. In Proceedings of the\nSixth ACM SIGKDD International Conference on Knowledge Discovery\nand Data Mining , 10 pages, pp. 179\u2014-188. Association for Computing\nMachinery, New York, NY , USA, 2000. doi: 10.1145/347090.347124 2\n[3]D. Antweiler and G. Fuchs. Visualizing rule-based classifiers for clinical\nrisk prognosis. In IEEE Visualization and Visual Analytics , pp. 55\u201359.\nIEEE, 2022. doi: 10.1109/vis54862.2022.00020 2, 3\n[4]M. Aria, C. Cuccurullo, and A. Gnasso. A comparison among interpreta-\ntive proposals for random forests. Machine Learning with Applications ,\n6:100094, 2021. doi: 10.1016/j.mlwa.2021.100094 2, 3\n[5]M. Aria, A. Gnasso, C. Iorio, and G. Pandolfo. Explainable ensemble\ntrees. Computational Statistics , pp. 3\u201319, 2023. doi: 10.1007/s00180-022\n-01312-6 3\n[6]G. Bakirli and D. Birant. Dtreesim: A new approach to compute decision\ntree similarity using re-mining. Turkish Journal of Electrical Engineering\nand Computer Sciences , 25(1):108\u2013125, 2017. doi: 10.3906/elk-1504-234\n3, 4\n[7]M. Banerjee, Y . Ding, and A.-M. Noone. Identifying representative trees\nfrom ensembles. Statistics in Medicine , 31(15):1601\u20131616, 2012. doi: 10.\n1002/sim.4492 3, 4\n[8]T. Barlow and P. Neville. Case study: visualization for decision tree\nanalysis in data mining. In IEEE Symposium on Information Visualization ,\npp. 149\u2013152, 2001. doi: 10.1109/INFVIS.2001.963292 1, 2\n[9]A. Bouchet, M. Sesma-Sara, G. Ochoa, H. Bustince, S. Montes, and\nI. D\u00edaz. Measures of embedding for interval-valued fuzzy sets. Fuzzy Sets\nand Systems , 467:108505, 2023. doi: 10.1016/j.fss.2023.03.008 4\n[10] L. Breiman. Random forests. Machine learning , 45:5\u201332, 2001. doi: 10.\n1023/A:1010933404324 1\n[11] S. Bremm, T. von Landesberger, M. He\u00df, T. Schreck, P. Weil, and\nK. Hamacherk. Interactive visual comparison of multiple trees. In IEEE\nConference on Visual Analytics Science and Technology , pp. 31\u201340, 2011.\ndoi: 10.1109/V AST.2011.6102439 2\n[12] J. Brooke. Sus-a quick and dirty usability scale. Usability evaluation in\nindustry , 189(194):1\u20136, 1996. doi: 10.1201/9781498710411-35 2, 8\n[13] A. Chatzimparmpas, R. M. Martins, I. Jusufi, K. Kucher, F. Rossi, and\nA. Kerren. The state of the art in enhancing trust in machine learning\nmodels with the use of visualizations. In Computer Graphics Forum ,\nvol. 39, pp. 713\u2013756. Wiley Online Library, 2020. doi: 10.1111/cgf.14034\n1\n[14] A. Chatzimparmpas, R. M. Martins, and A. Kerren. Visruler: Visual\nanalytics for extracting decision rules from bagged and boosted decision\ntrees. Information Visualization , 22(2):115\u2013139, 2023. doi: 10.1177/\n14738716221142005 1, 2, 3, 7\n[15] C.-h. Chen, W. H\u00e4rdle, A. Unwin, and S. Urbanek. Visualizing trees\nand forests. Handbook of data visualization , pp. 243\u2013264, 2008. doi: 10.\n1007/978-3-540-33037-0_11 2\n[16] H. A. Chipman, E. I. George, and R. E. McCulloch. Extracting repre-\nsentative tree models from a forest. IPT Group, IT Division, CERN , pp.\n363\u2013377, 1998. 3, 4\n[17] J. Eirich, M. M\u00fcnch, D. J\u00e4ckle, M. Sedlmair, J. Bonart, and T. Schreck.\nRfx: a design study for the interactive exploration of a random forest to\nenhance testing procedures for electrical engines. In Computer Graphics\nForum , vol. 41, pp. 302\u2013315. Wiley Online Library, 2022. doi: 10.1111/cgf\n.14452 3, 4, 7\n[18] N. Elmqvist and J. Fekete. Hierarchical aggregation for information visual-\nization: Overview, techniques, and design guidelines. IEEE Transactions\non Visualization and Computer Graphics , 16(3):439\u2013454, 2009. doi: 10.\n1109/TVCG.2009.84 2\n[19] V . A. Epanechnikov. Non-parametric estimation of a multivariate proba-\nbility density. Theory of Probability & its Applications , 14(1):153\u2013158,\n1969. doi: 10.1137/1114019 4\n[20] B. Everitt, S. Landau, M. Leese, and D. Stahl. Hierarchical Clustering ,\nchap. 4, pp. 71\u2013110. John Wiley & Sons, Ltd, 2011. doi: 10.1002/9780470977811.ch4 4\n[21] B. German. Glass Identification. UCI Machine Learning Repository, 1987.\ndoi: 10.24432/C5WW2P. 2, 5, 7\n[22] M. Graham and J. Kennedy. A survey of multiple tree visualisation.\nInformation Visualization , 9(4):235\u2013252, 2009. doi: 10.1057/ivs.2009.29\n2\n[23] L. Grinsztajn, E. Oyallon, and G. Varoquaux. Why do tree-based models\nstill outperform deep learning on typical tabular data? Advances in Neural\nInformation Processing Systems , 35:507\u2013520, 2022. doi: 10.48550/arXiv.\n2207.08815 1\n[24] J. Han and N. Cercone. Ruleviz: a model for visualizing knowledge\ndiscovery process. In Proceedings of the sixth ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining , pp. 244\u2013253, 2000.\ndoi: 10.1145/347090.347139 2\n[25] A. Hinterreiter, P. Ruch, H. Stitz, M. Ennemoser, J. Bernard, H. Strobelt,\nand M. Streit. Confusionflow: A model-agnostic visualization for temporal\nanalysis of classifier confusion. IEEE Transactions on Visualization and\nComputer Graphics , 28(2):1222\u20131236, 2020. doi: 10.1109/tvcg.2020.\n3012063 2\n[26] A. M. Horst, A. P. Hill, and K. B. Gorman. palmerpenguins: Palmer\nArchipelago (Antarctica) penguin data , 2020. doi: 10.5281/zenodo.\n3960218 5, 7\n[27] V . Y . Kulkarni and P. K. Sinha. Pruning of random forest classifiers: A\nsurvey and future directions. In International Conference on Data Science\n& Engineering , pp. 64\u201368. IEEE, 2012. doi: 10.1109/icdse.2012.6282329\n2\n[28] B.-H. Laabs, A. Westenberger, and I. R. K\u00f6nig. Identification of represen-\ntative trees in random forests based on a new tree-based distance measure.\nAdvances in Data Analysis and Classification , pp. 1\u201318, 2023. doi: 10.\n1007/s11634-023-00537-7 3, 4, 9\n[29] P. Langfelder, B. Zhang, and S. Horvath. Defining clusters from a hier-\narchical cluster tree: the dynamic tree cut package for r. Bioinformatics ,\n24(5):719\u2013720, 2008. doi: 10.1093/bioinformatics/btm563 4\n[30] V . I. Levenshtein et al. Binary codes capable of correcting deletions,\ninsertions, and reversals. In Soviet Physics Doklady , vol. 10, pp. 707\u2013710.\nSoviet Union, 1966. 3\n[31] G. Li, Y . Zhang, Y . Dong, J. Liang, J. Zhang, J. Wang, M. J. McGuffin, and\nX. Yuan. Barcodetree: Scalable comparison of multiple hierarchies. IEEE\nTransactions on Visualization and Computer Graphics , 26(1):1022\u20131032,\n2019. doi: 10.1109/tvcg.2019.2934535 2\n[32] Y . Liu and G. Salvendy. Design and evaluation of visualization support\nto facilitate decision trees classification. International Journal of Human-\nComputer Studies , 65:95\u2013110, 02 2007. doi: 10.1016/j.ijhcs.2006.07.005\n2\n[33] Z. Liu, S. H. Zhan, and T. Munzner. Aggregated dendrograms for visual\ncomparison between many phylogenetic trees. IEEE Transactions on\nVisualization and Computer Graphics , 26(9):2732\u20132747, 2020. doi: 10.\n1109/TVCG.2019.2898186 2\n[34] D. Mazumdar, M. P. Neto, and F. V . Paulovich. Random forest similarity\nmaps: A scalable visual representation for global and local interpretation.\nElectronics , 10(22):2862, 2021. doi: 10.3390/electronics10222862 3\n[35] C. Ma\u00e7\u00e3s, J. R. Campos, N. Louren\u00e7o, and P. Machado. Visualisation of\nrandom forest classification. Information Visualization , 23(4):312\u2013327,\n2024. doi: 10.1177/14738716241260745 1\n[36] N. M\u00e9doc, V . Ciorna, F. Petry, and M. Ghoniem. Visualizing prediction\nprovenance in regression random forests. In EuroVis (Posters) , pp. 75\u201377.\nThe Eurographics Association, 2022. doi: 10.2312/evp.20221124 2, 3\n[37] L. Meng, S. van den Elzen, and A. Vilanova. Modelwise: Interactive model\ncomparison for model diagnosis, improvement and selection. Computer\nGraphics Forum , 41(3):97\u2013108, 2022. doi: 10.1111/cgf.14525 2\n[38] Y . Ming, H. Qu, and E. Bertini. Rulematrix: Visualizing and understanding\nclassifiers with rules. IEEE Transactions on Visualization and Computer\nGraphics , 25(1):342\u2013352, 2018. doi: 10.1109/tvcg.2018.2864812 2\n[39] T. M\u00fchlbacher, L. Linhardt, T. M\u00f6ller, and H. Piringer. Treepod:\nSensitivity-aware selection of pareto-optimal decision trees. IEEE Trans-\nactions on Visualization and Computer Graphics , 24(1):174\u2013183, 2017.\ndoi: 10.1109/tvcg.2017.2745158 2, 3\n[40] T. Munzner, F. Guimbreti\u00e8re, S. Tasiran, L. Zhang, and Y . Zhou. Treejux-\ntaposer: scalable tree comparison using focus+context with guaranteed\nvisibility. In SIGGRAPH , pp. 453\u2013\u2013462. Association for Computing\nMachinery, New York, NY , USA, 2003. doi: 10.1145/1201775.882291 2\n[41] M. P. Neto and F. V . Paulovich. Explainable matrix-visualization for global\nand local interpretability of random forest classification ensembles. IEEE\n10\n\n--- Page 11 ---\n\u00a92025 IEEE. This is the author\u2019s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The final version of this record is available at: xx.xxxx/TVCG.201x.xxxxxxx/\nTransactions on Visualization and Computer Graphics , 27(2):1427\u20131437,\n2020. doi: 10.1109/tvcg.2020.3030354 1, 3\n[42] A. Palczewska, J. Palczewski, R. Marchese Robinson, and D. Neagu. In-\nterpreting random forest classification models using a feature contribution\nmethod. Integration of Reusable Systems , pp. 193\u2013218, 2014. doi: 10.\n1007/978-3-319-04717-1_9 3\n[43] F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel,\nM. Blondel, P. Prettenhofer, R. Weiss, V . Dubourg, J. Vanderplas, A. Pas-\nsos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-\nlearn: Machine learning in Python. Journal of Machine Learning Research ,\n12:2825\u20132830, 2011. doi: 10.48550/arXiv.1201.0490 5\n[44] N. Rico, P. Huidobro, A. Bouchet, and I. D\u00edaz. Similarity measures for\ninterval-valued fuzzy sets based on average embeddings and its application\nto hierarchical clustering. Information Sciences , 615:794\u2013812, 2022. doi:\n10.1016/j.ins.2022.10.028 4\n[45] O. Sagi and L. Rokach. Explainable decision forest: Transforming a\ndecision forest into an interpretable tree. Information Fusion , 61:124\u2013138,\n2020. doi: 10.1016/j.inffus.2020.03.013 1\n[46] I. H. Sarker. Machine learning: Algorithms, real-world applications and\nresearch directions. SN Computer Science , 2(3):160, 2021. doi: 10.1007/\ns42979-021-00592-x 1\n[47] J. Sauro and J. R. Lewis. Quantifying the user experience: Practical\nstatistics for user research . Morgan Kaufmann, 2012. doi: 10.1016/C2010\n-0-65192-3 9\n[48] H. Schulz, S. Hadlak, and H. Schumann. The design space of implicit\nhierarchy visualization: A survey. IEEE Transactions on Visualization\nand Computer Graphics , 17(4):393\u2013411, April 2011. doi: 10.1109/TVCG\n.2010.79 2\n[49] W. D. Shannon and D. Banks. Combining classification trees using mle.\nStatistics in Medicine , 18(6):727\u2013740, 1999. doi: 10.1002/(sici)1097-0258\n(19990330)18:6<727::aid-sim61>3.0.co;2-2 3\n[50] B. W. Silverman. Density estimation for statistics and data analysis .\nRoutledge, 2018. doi: 10.1201/9781315140919 4\n[51] M. Sondag, C. Turkay, K. Xu, L. Matthews, S. Mohr, and D. Archambault.\nVisual analytics of contact tracing policy simulations during an emergency\nresponse. Computer Graphics Forum , 41(3):29\u201341, 2022. doi: 10.1111/\ncgf.14520 3\n[52] C. D. Stolper, A. Perer, and D. Gotz. Progressive visual analytics: User-\ndriven visual exploration of in-progress analytics. IEEE Transactions on\nVisualization and Computer Graphics , 20(12):1653\u20131662, 2014. doi: 10.\n1109/tvcg.2014.2346574 9\n[53] D. Streeb, Y . Metz, U. Schlegel, B. Schneider, M. El-Assady, H. Neth,\nM. Chen, and D. A. Keim. Task-based visual interactive modeling: deci-\nsion trees and rule-based classifiers. IEEE Transactions on Visualization\nand Computer Graphics , 28(9):3307\u20133323, 2021. doi: 10.1109/tvcg.2020.\n3045560 2, 3\n[54] S. Tan, M. Soloviev, G. Hooker, and M. T. Wells. Tree space prototypes:\nAnother look at making tree ensembles interpretable. In Proceedings of\nACM-IMS on Foundations of Data Science Conference , pp. 23\u201334, 2020.\ndoi: 10.1145/3412815.3416893 3\n[55] S. T. Teoh and K.-L. Ma. Paintingclass: interactive construction, visualiza-\ntion and exploration of decision trees. In Proceedings of the Ninth ACM\nSIGKDD International Conference on Knowledge Discovery and Data\nMining , pp. 667\u2014-672. Association for Computing Machinery, 2003. doi:\n10.1145/956750.956837 1, 2\n[56] S. van den Elzen and J. J. van Wijk. Baobabview: Interactive construction\nand analysis of decision trees. In IEEE Conference on Visual Analytics\nScience and Technology , pp. 151\u2013160, 2011. doi: 10.1109/V AST.2011.\n6102453 1, 2, 3, 6\n[57] A. van Der Ploeg. Drawing non-layered tidy trees in linear time. Software:\nPractice and Experience , 44(12):1467\u20131484, 2013. doi: 10.1002/spe.2213\n6\n[58] T. Vidal and M. Schiffer. Born-again tree ensembles. In International\nConference on Machine Learning , pp. 9743\u20139753. PMLR, 2020. doi: 10.\n48550/arXiv.2003.11132 1\n[59] A. V ogogias, J. Kennedy, D. Archaumbault, V . A. Smith, and H. Currant.\nMlcut: Exploring multi-level cuts in dendrograms for biological data.\nInComputer Graphics and Visual Computing Conference . Eurographics\nAssociation, 2016. doi: 10.2312/cgvc.20161288 9\n[60] E. Wall, M. Agnihotri, L. Matzen, K. Divis, M. Haass, A. Endert, and\nJ. Stasko. A heuristic approach to value-driven evaluation of visualizations.\nIEEE Transactions on Visualization and Computer Graphics , 25(1):491\u2013\n500, 2018. doi: 10.1109/tvcg.2018.2865146 2, 8, 9[61] Z. J. Wang, C. Zhong, R. Xin, T. Takagi, Z. Chen, D. H. Chau, C. Rudin,\nand M. Seltzer. Timbertrek: Exploring and curating sparse decision trees\nwith interactive visualization. In IEEE Visualization and Visual Analytics ,\npp. 60\u201364. IEEE, 2022. doi: 10.1109/vis54862.2022.00021 2, 3\n[62] S. H. Welling, H. H. F. Refsgaard, P. B. Brockhoff, and L. H. Clemmensen.\nForest floor visualizations of random forests. CoRR , abs/1605.09196,\n2016. doi: 10.48550/arXiv.1605.09196 3\n[63] W. Willett, J. Heer, and M. Agrawala. Scented widgets: Improving\nnavigation cues with embedded visualizations. IEEE Transactions on\nVisualization and Computer Graphics , 13(6):1129\u20131136, 2007. doi: 10.\n1109/tvcg.2007.70589 4\n[64] A. Worland, S. Wagle, and B. Kovalerchuk. Visualization of decision trees\nbased on general line coordinates to support explainable models. In 26th\nInternational Conference Information Visualisation , pp. 351\u2013358. IEEE,\n2022. doi: 10.1109/iv56949.2022.00065 2\n[65] X. Zhao, Y . Wu, D. L. Lee, and W. Cui. iforest: Interpreting random forests\nvia visual analytics. IEEE Transactions on Visualization and Computer\nGraphics , 25(1):407\u2013416, 2018. doi: 10.1109/tvcg.2018.2864475 1, 3, 7\n[66] B. Zheng and F. Sadlo. On the visualization of hierarchical multivariate\ndata. In Proceedings of IEEE Pacific Visualization Symposium , pp. 131\u2013\n140, 2021. doi: 10.1109/PacificVis52677.2021.00026 2\n11",
  "project_dir": "artifacts/projects/enhanced_cs.HC_2507.22665v1_Cluster_Based_Random_Forest_Visualization_and_Inte",
  "communication_dir": "artifacts/projects/enhanced_cs.HC_2507.22665v1_Cluster_Based_Random_Forest_Visualization_and_Inte/.agent_comm",
  "assigned_at": "2025-07-31T22:15:37.818395",
  "status": "assigned"
}